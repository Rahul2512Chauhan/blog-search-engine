{
  "title": "Connecting the Dots for Better Movie Recommendations",
  "author": "Brian Godsey",
  "date": "2025-06-12T19:27:55-05:00",
  "content": "The world’s leading publication for data science, AI, and ML professionals.\n\n\t\t\tLightweight graph RAG on Rotten Tomatoes movie reviews\t\t\nOne of the promises of retrieval-augmented generation (RAG) is that it allows AI systems to answer questions using up-to-date or domain-specific information, without retraining the model. But most RAG pipelines still treat documents and information as flat and disconnected—retrieving isolated chunks based on vector similarity, with no sense of how those chunks relate.\nIn order to remedy RAG’s ignorance of—often obvious—connections between documents and chunks, developers have turned to graph RAG approaches, but often found that the benefits of graph RAG were not worth the added complexity of implementing it. \nIn our recent article on the open-source Graph RAG Project and GraphRetriever, we introduced a new, simpler approach that combines your existing vector search with lightweight, metadata-based graph traversal, which doesn’t require graph construction or storage. The graph connections can be defined at runtime—or even query-time—by specifying which document metadata values you would like to use to define graph “edges,” and these connections are traversed during retrieval in graph RAG.\nIn this article, we expand on one of the use cases in the Graph RAG Project documentation—a demo notebook can be found here—which is a simple but illustrative example: searching movie reviews from a Rotten Tomatoes dataset, automatically connecting each review with its local subgraph of related information, and then putting together query responses with full context and relationships between movies, reviews, reviewers, and other data and metadata attributes.\nThe dataset used in this case study comes from a public Kaggle dataset titled “Massive Rotten Tomatoes Movies and Reviews”. It includes two primary CSV files:\nEach review is linked to a movie via a shared movie_id, creating a natural relationship between unstructured review content and structured movie metadata. This makes it a perfect candidate for demonstrating GraphRetriever’s ability to traverse document relationships using metadata alone—no need to manually build or store a separate graph.\nBy treating metadata fields such as movie_id, genre, or even shared actors and directors as graph edges, we can build a connected retrieval flow that enriches each query with related context automatically.\nA common goal in AI-powered search and recommendation systems is to let users ask natural, open-ended questions and get meaningful, contextual results. With a large dataset of movie reviews and metadata, we want to support full-context responses to prompts like:\nA great answer to each of these prompts requires subjective review content along with some semi-structured attributes like genre, audience, or visual style. To give a good answer with full context, the system needs to:\nA traditional RAG pipeline might handle step 1 well—pulling relevant snippets of text. But, without knowledge of how the retrieved chunks relate to other information in the dataset, the model’s responses can lack context, depth, or accuracy. \nGiven a user’s query, a plain RAG system might recommend a movie based on a small set of directly semantically relevant reviews. But graph RAG and GraphRetriever can easily pull in relevant context—for example, other reviews of the same movies or other movies in the same genre—to compare and contrast before making recommendations.\nFrom an implementation standpoint, graph RAG provides a clean, two-step solution:\nFirst, just like with any RAG system, we embed the document text using a language model and store the embeddings in a vector database. Each embedded review may include structured metadata, such as reviewed_movie_id, rating, and sentiment—information we’ll use to define relationships later. Each embedded movie description includes metadata such as movie_id, genre, release_year, director, etc.\nThis allows us to handle typical vector-based retrieval: when a user enters a query like “What are some good family movies?”, we can quickly fetch reviews from the dataset that are semantically related to family movies. Connecting these with broader context occurs in the next step.\nOnce the semantically relevant reviews are retrieved in step 1 using vector search, we can then use GraphRetriever to traverse connections between reviews and their related movie records.\nSpecifically, the GraphRetriever:\nA key point: no pre-built knowledge graph is needed. The graph is defined entirely in terms of metadata and traversed dynamically at query time. If you want to expand the connections to include shared actors, genres, or time periods, you just update the edge definitions in the retriever config—no need to reprocess or reshape the data.\nSo, when a user asks about exciting action movies with some specific qualities, the system can bring in datapoints like the movie’s release year, genre, and cast, improving both relevance and readability. When someone asks about classic movies with amazing cinematography, the system can draw on reviews of older films and pair them with metadata like genre or era, giving responses that are both subjective and grounded in facts.\nIn short, GraphRetriever bridges the gap between unstructured opinions (subjective text) and structured context (connected metadata)—producing query responses that are more intelligent, trustworthy, and complete.\nTo show how GraphRetriever can connect unstructured review content with structured movie metadata, we walk through a basic setup using a sample of the Rotten Tomatoes dataset. This involves three main steps: creating a vector store, converting raw data into LangChain documents, and configuring the graph traversal strategy.\nSee the example notebook in the Graph RAG Project for complete, working code.\nWe begin by embedding and storing the documents, just like we would in any RAG system. Here, we are using OpenAIEmbeddings and the Astra DB vector store:\nWe store and embed document content as we usually would for any RAG system, but we also preserve structured metadata for use in graph traversal. The document content is kept minimal (review text, movie title, description), while the rich structured data is stored in the “metadata” fields in the stored document object.\nThis is example JSON from one movie document in the vector store:\nNote that graph traversal with GraphRetriever uses only the attributes this metadata field, does not require a specialized graph DB, and does not use any LLM calls or other expensive \nThe GraphRetriever traverses a simple graph defined by metadata connections. In this case, we define an edge from each review to its corresponding movie using the directional relationship between reviewed_movie_id (in reviews) and movie_id (in movie descriptions).\nWe use an “eager” traversal strategy, which is one of the simplest traversal strategies. See documentation for the Graph RAG Project for more details about strategies.\nIn this configuration:\nNote that because each review links to exactly one reviewed movie, the graph traversal depth would have stopped at 1 regardless of this parameter, in this simple example. See more examples in the Graph RAG Project for more sophisticated traversal.\nYou can now run a natural language query, such as:\nAnd with a little sorting and reformatting of text—see the notebook for details—we can print a basic list of the retrieved movies and reviews, for example:\nWe can then pass the above output to the LLM for generation of a final response, using the full set information from the reviews as well as the linked movies.\nSetting up the final prompt and LLM call looks like this:\nAnd, the final response from the graph RAG system might look like this:\nBased on the reviews provided, \"The Addams Family\" and \"Addams Family Values\" are recommended as good family movies. \"The Addams Family\" is described as a witty family comedy with enough humor to entertain adults, while \"Addams Family Values\" is noted for its clever take on family dynamics and its entertaining moments.\nKeep in mind that this final response was the result of the initial semantic search for reviews mentioning family movies—plus expanded context from documents that are directly related to these reviews. By expanding the window of relevant context beyond simple semantic search, the LLM and overall graph RAG system is able to put together more complete and more helpful responses.\nThe case study in this article shows how to:\nIn short, this is Graph RAG in action: adding structure and relationships to make LLMs not just retrieve, but build context and reason more effectively. If you’re already storing rich metadata alongside your documents, GraphRetriever gives you a practical way to put that metadata to work—with no additional infrastructure.\nWe hope this inspires you to try GraphRetriever on your own data—it’s all open-source—especially if you’re already working with documents that are implicitly connected through shared attributes, links, or references.\nYou can explore the full notebook and implementation details here: Graph RAG on Movie Reviews from Rotten Tomatoes.\nWritten By\nTopics:\nShare this article:\nA deep dive on the meaning of understanding and how it applies to LLMs \nExplore the nuances of the transformer architecture behind Llama 3 and its prospects for the… \nExplore the details behind the power of transformers \nExplore the secret behind Sora’s state-of-the-art videos \nHow could AI suggest your majors? \nYou may choose suboptimal prompts for your LLM (or make other suboptimal choices via model… \nIf you are on social media like Twitter or LinkedIn, you have probably noticed that… \nYour home for data science and Al. The world’s leading publication for data science, data analytics, data engineering, machine learning, and artificial intelligence professionals.\nThese cookies enable the website to provide enhanced functionality and personalisation. They may be set by us or by third party providers whose services we have added to our pages. If you do not allow these cookies then some or all of these services may not function properly.\nThese cookies are necessary for the website to function and cannot be switched off in our systems. They are usually only set in response to actions made by you which amount to a request for services, such as setting your privacy preferences, logging in or filling in forms. You can set your browser to block or alert you about these cookies, but some parts of the site will not then work. These cookies do not store any personally identifiable information.\nThese cookies allow us to count visits and traffic sources so we can measure and improve the performance of our site. They help us to know which pages are the most and least popular and see how visitors move around the site. All information these cookies collect is aggregated and therefore anonymous. If you do not allow these cookies we will not know when you have visited our site, and will not be able to monitor its performance.\nThese cookies may be set through our site by our advertising partners. They may be used by those companies to build a profile of your interests and show you relevant adverts on other sites. They do not store directly personal information, but are based on uniquely identifying your browser and internet device. If you do not allow these cookies, you will experience less targeted advertising.\n\nDesign Smarter Prompts and Boost Your LLM Output: Real Tricks from an AI Engineer’s Toolbox | Towards Data Science\nModel Context Protocol (MCP) Tutorial: Build Your First MCP Server in 6 Steps | Towards Data Science\nLLMs + Pandas: How I Use Generative AI to Generate Pandas DataFrame Summaries | Towards Data Science\nEvaluating LLMs for Inference, or Lessons from Teaching for Machine Learning | Towards Data Science",
  "url": "https://towardsdatascience.com/connecting-the-dots-for-better-movie-recommendations/"
}